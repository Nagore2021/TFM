import streamlit as st
import sys
import logging
import os
import time
from typing import Optional
from transformers import pipeline as hf_pipeline
import langid
import torch

# Imports del proyecto 
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from medical_rag_produccion import MedicalRAGProduction, MedicalResponse
from retrieval.chroma_utils import translate_eu_to_es
from embeddings.load_model import cargar_configuracion

# Imports para memoria conversacional
from langchain.memory import ConversationSummaryBufferMemory

# Logger
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# Configuraci√≥n de p√°gina y estilo global
st.set_page_config(
    page_title="Osasun Laguntzailea / Asistente M√©dico",
    page_icon="üè•",
    layout="wide"
)

# CSS para mejorar la UI
st.markdown(
    """
    <style>
      /* Fondo y contenedor principal */
      body, .block-container {
        background-color: #f5f7fa;
        padding: 20px;
      }
      /* T√≠tulo principal  */
      .main-title {
        text-align: center;
        font-size: 2.8rem;
        font-weight: 800;
        background: linear-gradient(90deg, #006BB6, #00c6ff);
        
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 0.2rem;
      }
      /* Subt√≠tulo con borde inferior */
      .subtitle {
        text-align: center;
        color: #6c757d;
        font-size: 1.1rem;
        margin-top: 0;
        border-bottom: 2px solid #e9ecef;
        padding-bottom: 0.5rem;
      }
      /* Aviso m√©dico */
      .medical-warning {
        background: #fffbea;
        border-left: 6px solid #ffc107;
        padding: 18px;
        border-radius: 10px;
        color: #856404;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        margin-bottom: 20px;
      }
      /* Badge de idioma */
      .language-badge {
        background: #e2e3e5;
        padding: 6px 14px;
        border-radius: 20px;
        font-size: 0.85rem;
        color: #495057;
        display: inline-block;
        margin-top: 10px;
        margin-bottom: 10px;
      }
      /* Informaci√≥n del chunk recuperado */
      .chunk-info {
        background: #e8f4f8;
        border-left: 4px solid #0072ff;
        padding: 12px;
        border-radius: 6px;
        font-size: 0.85rem;
        color: #0056b3;
        margin: 10px 0;
      }
      /* Tiempo de procesamiento */
      .processing-time {
        background: #f8f9fa;
        padding: 8px 12px;
        border-radius: 6px;
        font-size: 0.8rem;
        color: #6c757d;
        text-align: right;
        margin-top: 10px;
      }
      /* Burbujas de chat mejoradas */
      .user-message {
        background-color: #d1e7dd;
        padding: 12px 16px;
        border-radius: 15px 15px 0 15px;
        color: #155724;
        box-shadow: 0 1px 4px rgba(0,0,0,0.1);
        margin: 8px 0;
      }
      .assistant-message {
        background-color: #f0f8ff;
        padding: 12px 16px;
        border-radius: 15px 15px 15px 0;
        color: #2c3e50;
        box-shadow: 0 1px 4px rgba(0,0,0,0.1);
        margin: 8px 0;
        border-left: 4px solid #0072ff;
      }
      /* Botones primarios */
      .stButton > button {
        background-color: #0072ff;
        color: #ffffff;
        border-radius: 6px;
        padding: 8px 16px;
        font-weight: 600;
      }
      .stButton > button:hover {
        background-color: #005bb5;
        color: #ffffff;
      }
      /* Input de chat con sombra */
      .stChatInput > div {
        box-shadow: 0 1px 4px rgba(0,0,0,0.1);
        border-radius: 20px;
        padding: 4px;
      }
    </style>
    """,
    unsafe_allow_html=True
)

# Inicializar langid , configurando idiomas
langid.set_languages(['eu', 'es'])

def is_euskera(text: str) -> bool:
    """Detecta si el texto est√° en euskera """
    lang, conf = langid.classify(text)
    logger.info(f"langid ‚Üí texto: '{text[:50]}...' ‚Üí idioma: {lang}, confianza: {conf:.2f}")
    
    # Solo usar langid con umbral m√°s permisivo
    is_euskera_detected = (lang == 'eu')  # Sin umbral de confianza
    
    logger.info(f"Detecci√≥n final: euskera={is_euskera_detected}")
    return is_euskera_detected

@st.cache_resource  # Decorador para cach√© de recursos, evita recargar en cada ejecuci√≥n y carga una vez
def load_euskera_translator():
    """Carga el traductor euskera‚Üíespa√±ol usando tu configuraci√≥n"""
    try:
        logger.info("Cargando traductor euskera‚Üíespa√±ol...")
        
        # Usar tu funci√≥n de configuraci√≥n
        cfg = cargar_configuracion("../config.yaml")
        
        import torch
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # Cargar traductor con tu configuraci√≥n
        translator = hf_pipeline(
            'translation', 
            model=cfg['model']['translation_model'],
            device=0 if device=="cuda" else -1
        )
        logger.info("Traductor euskera‚Üíespa√±ol cargado exitosamente")
        return translator
    except Exception as e:
        logger.error(f"Error cargando traductor euskera‚Üíespa√±ol: {e}")
        return None

@st.cache_resource
def load_reverse_translator():
    """Carga traductor espa√±ol ‚Üí euskera (para respuestas)"""
    try:
        logger.info("Cargando traductor espa√±ol‚Üíeuskera...")
        
        import torch
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        reverse_translator = hf_pipeline(
            'translation', 
            model="Helsinki-NLP/opus-mt-es-eu", 
            device=0 if device=="cuda" else -1
        )
        logger.info("Traductor espa√±ol‚Üíeuskera cargado exitosamente")
        return reverse_translator
    except Exception as e:
        logger.error(f"Error cargando traductor espa√±ol‚Üíeuskera: {e}")
        return None

@st.cache_resource
def load_rag_system() -> Optional[MedicalRAGProduction]:
    """Carga el sistema RAG m√©dico de producci√≥n con memoria conversacional"""
    try:
        logger.info("Inicializando sistema RAG m√©dico...")
        
        # Crear sistema RAG (silencioso para Streamlit)
        rag = MedicalRAGProduction(
            config_path="../config.yaml",
            mode="embedding",
            verbose=False  # para evitar logs excesivos en Streamlit
        )
        
        # Inicializar sistema
        if rag.initialize():
            logger.info("Sistema RAG inicializado correctamente")
            
            # VERIFICAR que el LLM existe antes de crear memoria
            if hasattr(rag, 'llm') and rag.llm is not None:
                # Crear memoria conversacional
                memory = ConversationSummaryBufferMemory(
                    llm=rag.llm, 
                    max_token_limit=150,
                    memory_key="chat_history",
                    return_messages=True
                )
                rag.memory = memory
                logger.info("Memoria conversacional activada")
            else:
                logger.warning("LLM no disponible, memoria desactivada")
                rag.memory = None
            
            return rag
        else:
            logger.error("Error en inicializaci√≥n del sistema RAG")
            return None
            
    except Exception as e:
        logger.error(f"Error cargando RAG: {e}")
        return None

def translate_euskera_to_spanish(text: str, translator) -> str:
    """Usa tu funci√≥n existente de chroma_utils con traductor independiente"""
    if translator is not None:
        translated = translate_eu_to_es(text, translator)
        logger.info(f"Traducci√≥n: '{text}' ‚Üí '{translated}'")
        return translated
    else:
        logger.warning("No hay traductor disponible")
        return text

def translate_spanish_to_euskera(text: str, translator) -> str:
    """
    Traduce texto de espa√±ol a euskera - Similar a tu funci√≥n existente
    """
    if translator is None or not text:
        return text
    try:
        # Usar el mismo patr√≥n que tu funci√≥n translate_eu_to_es
        return translator([text])[0]["translation_text"]
    except Exception as e:
        logger.error(f"Traducci√≥n es‚Üíeu fallida: {e}")
        return text

def process_medical_query_with_memory(rag_system, spanish_query, original_query, is_euskera, reverse_translator):
    """
    Procesa consulta m√©dica con memoria y traducci√≥n de respuesta
    """
    start_time = time.time()
    
    try:
        # 1. Verificar si hay memoria disponible
        if hasattr(rag_system, 'memory') and rag_system.memory is not None:
            memory_vars = rag_system.memory.load_memory_variables({})
            
            if memory_vars.get('chat_history'):
                # A√±adir contexto del historial
                contextualized_query = f"Historial m√©dico previo: {memory_vars['chat_history']}\n\nConsulta actual: {spanish_query}"
            else:
                contextualized_query = spanish_query
            
            # Obtener respuesta del RAG (en espa√±ol)
            response = rag_system.ask_doctor(contextualized_query)
            
            # 2. Si la consulta era en euskera, traducir la respuesta
            if is_euskera and reverse_translator and response.success:
                try:
                    # Guardar respuesta original en espa√±ol (para memoria)
                    spanish_response = response.answer
                    
                    # Traducir respuesta a euskera
                    euskera_response = translate_spanish_to_euskera(response.answer, reverse_translator)
                    response.answer = euskera_response
                    logger.info("Respuesta traducida al euskera")
                    
                    # Guardar en memoria (en espa√±ol para coherencia)
                    rag_system.memory.save_context(
                        {"input": spanish_query},
                        {"output": spanish_response}  # Respuesta original en espa√±ol
                    )
                except Exception as e:
                    logger.warning(f"Error traduciendo respuesta: {e}")
                    response.answer = f"[Respuesta en espa√±ol - error de traducci√≥n]\n\n{response.answer}"
                    
                    # Guardar en memoria de todas formas
                    if response.success:
                        rag_system.memory.save_context(
                            {"input": spanish_query},
                            {"output": response.answer}
                        )
            else:
                # Respuesta en espa√±ol, guardar directamente si hay memoria
                if response.success and rag_system.memory:
                    rag_system.memory.save_context(
                        {"input": spanish_query},
                        {"output": response.answer}
                    )
        else:
            # Sin memoria, funciona como antes
            logger.info("Procesando sin memoria conversacional")
            response = rag_system.ask_doctor(spanish_query)
            
            # Traducir si es necesario
            if is_euskera and reverse_translator and response.success:
                try:
                    euskera_response = translate_spanish_to_euskera(response.answer, reverse_translator)
                    response.answer = euskera_response
                except Exception as e:
                    logger.warning(f"Error traduciendo: {e}")
        
        return response
        
    except Exception as e:
        logger.error(f"Error procesando consulta: {e}")
        # Fallback
        return rag_system.ask_doctor(spanish_query)

def format_medical_response(response: MedicalResponse, is_euskera: bool = False) -> str:
    """Formatea la respuesta m√©dica para Streamlit"""
    
    if not response.success:
        error_msg = "Barkatu, errorea gertatu da" if is_euskera else "Lo siento, ocurri√≥ un error"
        return f"**{error_msg}:**\n\n{response.answer}"
    
    title = "OSASUN ERANTZUNA" if is_euskera else "RESPUESTA M√âDICA"
    
    # Formatear respuesta principal
    formatted_response = f"**{title}:**\n\n{response.answer}"
    
    return formatted_response

def show_chunk_info(response: MedicalResponse):
    """Muestra informaci√≥n del chunk recuperado"""
    if response.success and response.chunk_used:
        chunk = response.chunk_used
        
        info_html = f"""
        <div class="chunk-info">
            <strong>Informaci√≥n recuperada:</strong><br>
            ‚Ä¢ <strong>Documento:</strong> {chunk.get('document_id', 'No especificado')}<br>
            ‚Ä¢ <strong>Archivo:</strong> {chunk.get('filename', 'No especificado')}<br>
            ‚Ä¢ <strong>Categor√≠a:</strong> {chunk.get('categoria', 'No especificada')}<br>
            ‚Ä¢ <strong>Estrategia:</strong> {chunk.get('strategy_used', 'No especificada')}
        </div>
        """
        st.markdown(info_html, unsafe_allow_html=True)

        
        chunk_text = chunk.get('text', 'Texto no disponible')
        
        # Crear un expander para el texto completo
        with st.expander(" Ver contenido utilizado como contexto", expanded=False):
            st.text_area(
                "Texto enviado al LLM:",
                value=chunk_text,
                height=200,
                disabled=True,
                help="Este es el fragmento de texto que se utiliz√≥ como contexto para generar la respuesta"
            )
            
            # Informaci√≥n adicional del texto
            st.caption(f" Longitud: {len(chunk_text)} caracteres | {len(chunk_text.split())} palabras")

def show_processing_time(processing_time: float):
    """Muestra el tiempo de procesamiento"""
    time_html = f"""
    <div class="processing-time">
        Procesado en {processing_time:.2f} segundos
    </div>
    """
    st.markdown(time_html, unsafe_allow_html=True)

def add_simple_controls(rag_system):
    """
    Controles m√≠nimos sin sidebar
    """
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col2:  # Centrado
        if st.button("Limpiar Chat", type="secondary"):
            st.session_state.messages = []
            # Limpiar memoria si existe
            if rag_system and hasattr(rag_system, 'memory') and rag_system.memory:
                rag_system.memory.clear()
                st.success("Chat y memoria limpiados")
            else:
                st.success("Chat limpiado")
            st.rerun()

def main():
    # Cabecera principal
    st.markdown('<h1 class="main-title">Osasun Eskola</h1>', unsafe_allow_html=True)
    st.markdown('<p class="subtitle">Sistema RAG M√©dico / Osasun RAG Sistema</p>', unsafe_allow_html=True)
    
    # Cargar componentes del sistema
    with st.spinner("Cargando sistema m√©dico..."):
        euskera_translator = load_euskera_translator()  # euskera‚Üíespa√±ol
        reverse_translator = load_reverse_translator()  # espa√±ol‚Üíeuskera
        rag_system = load_rag_system()
    
    # Verificar si el sistema est√° disponible
    if not rag_system:
        st.error("**Sistema m√©dico no disponible**")
        st.stop()

    
 
    if torch.cuda.is_available():
        st.success(f"GPU activa: {torch.cuda.get_device_name(0)}")
    else:
        st.warning("GPU no detectada. Ejecutando en CPU")
    
    # Aviso m√©dico
    st.markdown(
        '<div class="medical-warning">'
        '<strong>AVISO M√âDICO / OHAR MEDIKOA:</strong><br>'
        'Sistema de informaci√≥n m√©dica  para orientaci√≥n general. '
        '<strong>NO SUSTITUYE a la consulta m√©dica profesional.</strong><br>'
        '<strong>Osakidetzako informazio medikoko sistema orientazio orokorrerako. '
        'Ez du ordeztzen kontsulta mediko profesionala.</strong><br>'
        '<strong>Emergencias / Larrialdiak: 112</strong>'
        '</div>',
        unsafe_allow_html=True
    )
    
    # Controles simples
    add_simple_controls(rag_system)
    
    # Inicializar historial de chat
    if "messages" not in st.session_state:
        st.session_state.messages = []
        welcome = (
            "**Kaixo! Osasun laguntzailea naiz**\n\n"
            "Gaixotasunen inguruko galderak erantzuteko hemen nago: "
            "sintomak, tratamenduak, zainketa egokiak...\n\n"
            "**¬°Hola! Soy tu asistente m√©dico**\n\n"
            "Estoy aqu√≠ para responder preguntas sobre salud: "
            "s√≠ntomas, tratamientos, cuidados apropiados...\n\n"
            "**¬øEn qu√© puedo ayudarte hoy? / Zertan lagun zaitzaket gaur?**"
        )
        st.session_state.messages.append({"role": "assistant", "content": welcome})
    
    # Mostrar historial de chat
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if message["role"] == "user":
                st.markdown(f'<div class="user-message">{message["content"]}</div>', unsafe_allow_html=True)
            else:
                st.markdown(f'<div class="assistant-message">{message["content"]}</div>', unsafe_allow_html=True)
    
    # Input del usuario
    if prompt := st.chat_input("Idatzi zure galdera hemen / Escribe tu pregunta aqu√≠..."):
        
        # Detectar idioma
        is_eu = is_euskera(prompt)
        language_badge = "Euskera" if is_eu else "Espa√±ol"
        
        # Mostrar pregunta del usuario
        with st.chat_message("user"):
            st.markdown(f'<div class="user-message">{prompt}</div>', unsafe_allow_html=True)
            st.markdown(f'<div class="language-badge">{language_badge}</div>', unsafe_allow_html=True)
        
        # A√±adir al historial
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # Procesar consulta
        with st.chat_message("assistant"):
            with st.spinner("Analizando consulta m√©dica..."):
                
                # Traducir consulta si es necesario (para procesamiento)
                if is_eu:
                    spanish_query = translate_euskera_to_spanish(prompt, euskera_translator)
                    st.info(f"**Procesando:** {spanish_query}")
                else:
                    spanish_query = prompt
                
                try:
                    # PROCESAR CON MEMORIA Y TRADUCCI√ìN
                    response = process_medical_query_with_memory(
                        rag_system, 
                        spanish_query,    # Para procesamiento RAG
                        prompt,          # Consulta original
                        is_eu,           # Si necesita traducir respuesta
                        reverse_translator # Traductor espa√±ol‚Üíeuskera
                    )
                    
                    # Formatear y mostrar respuesta (ya traducida si era necesario)
                    formatted_response = format_medical_response(response, is_eu)
                    st.markdown(f'<div class="assistant-message">{formatted_response}</div>', unsafe_allow_html=True)
                    
                    # Mostrar informaci√≥n adicional si fue exitoso
                    if response.success:
                        show_chunk_info(response)
                    
                    show_processing_time(response.processing_time)
                    
                    # A√±adir al historial de Streamlit
                    st.session_state.messages.append({"role": "assistant", "content": formatted_response})
                    
                except Exception as e:
                    error_msg = f"**Error del sistema:** {str(e)}"
                    st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})

if __name__ == "__main__":
    main()